{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7d26bb-f709-4517-ad12-31d8e4de76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0          Read this if youâ€™re traveling to Negril!!   \n",
      "1                                 Negril Trip Report   \n",
      "2                          Wonderful trip to Jamaica   \n",
      "3                                     Negril beaches   \n",
      "4  What I wish I new about getting around in Jamaica   \n",
      "\n",
      "                                            selftext  score  num_comments  \\\n",
      "0  I recently stayed at Coco La Palm in Negril, a...     72            29   \n",
      "1  (Leaving this report in hopes of helping someo...     35            30   \n",
      "2                                         Beautiful.     34             4   \n",
      "3                                                NaN     29             5   \n",
      "4  This is what I learned about getting around in...     27             9   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.reddit.com/r/JamaicaTourism/commen...  \n",
      "1  https://www.reddit.com/r/JamaicaTourism/commen...  \n",
      "2             https://www.reddit.com/gallery/1bcfpt5  \n",
      "3             https://www.reddit.com/gallery/1jlt33z  \n",
      "4  https://www.reddit.com/r/JamaicaTourism/commen...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tahjg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt') # got an error earlier, this is how it was resolved.\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ja_df = pd.read_csv('../jamaica_tourism_data.csv');\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "print(ja_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0a2288-02a6-4c88-91e8-26b0c61945df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "#ja_df.title.tolist()\n",
    "#ja_df.selftext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf094e-3dd7-4bf1-838b-90bca4717b0c",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cf1b7c1-ed2e-4c59-aa39-a53af0df39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the text so that we don't input dirty data to the model, reduce noise as best as possible.\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "     \n",
    "     # Normalize Unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "     # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.replace(\"\\n\\n\", \" \")  # Remove double line breaks\n",
    "    text = text.replace(\"\\n\", \" \")  # Remove any remaining single line breaks\n",
    "     # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "     \n",
    "    # Remove extra whitespaces and trim\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5b6c2d8-b5db-4aec-b4f5-5885e2720ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization is the process of splitting text into smaller units (words, sentences, or subwords).\n",
    "#This helps the model understand individual words rather than treating the whole text as one big chunk.\n",
    "def standardize_text(text):\n",
    "    #tokenize text\n",
    "    tokens = word_tokenize(text.lower()) #lowercase all words\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43390163-b038-42b3-863d-00e27ebea379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming reduces words to their root form so that similar words are treated the same.\n",
    "#This helps the model generalize better instead of seeing \"running\" and \"run\" as two different words.\n",
    "def stem_tokens(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b01c865c-cb68-43a6-800f-eca044d9b820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "score           0\n",
       "num_comments    0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a7e3de3-2519-4939-b7a5-b097c5470c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           object\n",
       "selftext        object\n",
       "score            int64\n",
       "num_comments     int64\n",
       "url             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4af597f-3e20-43c1-98ee-5ab0130e3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ja_df[ja_df.selftext.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ca86203-4604-42e4-a139-08770c070bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_df = ja_df.dropna(subset=['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11c9acf8-fd65-4301-b5ee-add9f1ab7296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "selftext        0\n",
       "score           0\n",
       "num_comments    0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1ccbe2c-061d-4f24-a6d1-8d1513769b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tahjg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\tahjg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tahjg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3341a47-2b60-4422-a960-f80bc7f8d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_df['selftext'] = ja_df['selftext'].apply(clean_text)\n",
    "ja_df['title'] = ja_df['title'].apply(clean_text)  \n",
    "ja_df['tokens'] = ja_df['selftext'].apply(standardize_text)\n",
    "ja_df['clean_tokens'] = ja_df['tokens'].apply(stem_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38bd1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_df.to_csv('cleaned_jamaica_tourism_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "747a023e-7f87-4ccf-ad3c-ee8eafa754dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ja_df.selftext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77292fb",
   "metadata": {},
   "source": [
    "# Anything after this cell is for experimenting and testing and learning. Please ignore "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10aca3-0a7f-413c-9067-f2b2f72032fd",
   "metadata": {},
   "source": [
    "# Creating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ea8af091-4858-4037-a55d-2ea246899dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "# Turning title and comments into embeddings\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize and get model output\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Use the mean of the hidden states\n",
    "\n",
    "# Get BERT embeddings for titles and comments\n",
    "ja_df['title_embeddings'] = ja_df['title'].apply(get_bert_embeddings)\n",
    "ja_df['selftext_embeddings'] = ja_df['selftext'].apply(get_bert_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "02f5dcd2-917c-4a69-b00c-1f280a1af033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'selftext', 'score', 'num_comments', 'url', 'tokens',\n",
       "       'clean_tokens', 'title_embeddings', 'selftext_embeddings',\n",
       "       'tokens_string'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4823b-794f-42f0-be5b-7d0b3d5261b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686,)\n",
      "(686,)\n",
      "(686, 4851)\n"
     ]
    }
   ],
   "source": [
    "print(ja_df['title_embeddings'].values.shape)\n",
    "print(ja_df['selftext_embeddings'].values.shape)\n",
    "#print(dense_tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b839bfed-c7b6-428c-bd2e-0c3b6a298485",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings_reshaped = ja_df['title_embeddings'].values.reshape(-1, 1)\n",
    "selftext_embeddings_reshaped = ja_df['selftext_embeddings'].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dded26-8a00-4cfa-bcad-bbd991f1e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 1)\n",
      "(686, 1)\n",
      "(686, 4851)\n"
     ]
    }
   ],
   "source": [
    "print(title_embeddings_reshaped.shape)\n",
    "print(selftext_embeddings_reshaped.shape)\n",
    "#print(dense_tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424089fb-17f9-4d76-aff9-35c98b0d9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Concatenate the embeddings for title, comments, and tokens\n",
    "#combined_embeddings = np.concatenate([title_embeddings_reshaped, \n",
    "                                    #  selftext_embeddings_reshaped, \n",
    "                                    #  dense_tfidf_matrix], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a99492-369d-45f8-b5d8-1a57e9147e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 4853)\n"
     ]
    }
   ],
   "source": [
    "#print(combined_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab88b2-6570-444c-9e70-b560f6e5052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the embeddings are in numpy array format\n",
    "#combined_embeddings = np.array(combined_embeddings)\n",
    "## Didn't bother using the combined_embeddings. Maybe another time. The code below is where I created the embeddings I actually used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9511a-0a86-4c30-9d14-c685ceb8b51e",
   "metadata": {},
   "source": [
    "# Make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "cd7352cd-573e-42d9-9a99-ec93bd92400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Initialize BERT for embeddings\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "\n",
    "# Generate embeddings for all posts\n",
    "print(\"Generating embeddings...\")\n",
    "ja_df['embedding'] = ja_df['title'] + \" \" + ja_df['selftext'].fillna('')\n",
    "ja_df['embedding'] = ja_df['embedding'].apply(lambda x: get_bert_embeddings(x[:1000]))  # Truncate long posts\n",
    "\n",
    "# Build FAISS index\n",
    "embeddings = np.stack(ja_df['embedding'].values).astype('float32')\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "def generate_llama_recommendation(query, top_k=3):\n",
    "    # Get similar posts using FAISS\n",
    "    query_embedding = get_bert_embeddings(query).astype('float32').reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    # Prepare context for LLM\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"Title: {ja_df.iloc[idx]['title']}\\nContent: {ja_df.iloc[idx]['selftext'][:500]}\"\n",
    "        for idx in indices[0]\n",
    "    )\n",
    "    \n",
    "    # Generate with Llama 3\n",
    "    prompt = f\"\"\"\n",
    "    You are a Jamaica travel expert. Based on these posts, suggest 3 best options to answer the traveler's question.\n",
    "    Start off wiht a greeting by saying \"Wah Gwaan?\"\n",
    "     Whenever you're finished, say that this was developed by Tahj Gordon.\n",
    "    Traveler's question: {query}\n",
    "    \n",
    "    Relevant posts:\n",
    "    {context}\n",
    "    \n",
    "    Provide recommendations in this format:\n",
    "    1. [Place/Activity]: [Brief description - why it's good for what they asked]\n",
    "    2. [Place/Activity]: [Description]\n",
    "    3. [Place/Activity]: [Description]\n",
    "    \n",
    "    Add practical tips if available.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model='llama3.2',\n",
    "        prompt=prompt,\n",
    "        options={'temperature': 0.7}\n",
    "    )\n",
    "    \n",
    "    return response['response']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1b8404c8-b8b0-4eec-ad18-5bfcf50e3d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wah Gwaan?\n",
      "\n",
      "Based on your interest in driving around Jamaica, I've got three top recommendations to get you behind the wheel:\n",
      "\n",
      "1. **Rent a car with an automatic transmission**: This is the most convenient option for navigating Jamaica's roads, especially if you're not comfortable with manual transmissions. Many major rental companies like Hertz, Avis, and Budget offer cars with automatics.\n",
      "2. **Book a private driver or chauffeur**: If you prefer not to drive yourself, consider booking a private driver for your 5-day trip. This option allows you to sit back, relax, and enjoy the scenery while someone else handles the driving. You can find private drivers through companies like Island Car Rental or local tourism boards.\n",
      "3. **Use public transportation**: Jamaica's public transportation system is affordable and accessible. For shorter trips, buses (called \"buses\" locally) are a great way to get around. You can also take taxis or ride-hailing services like Uber.\n",
      "\n",
      "Practical tips:\n",
      "\n",
      "* Make sure to obtain an International Driving Permit (IDP) if your home country's license isn't recognized in Jamaica.\n",
      "* Be prepared for narrow, winding roads and aggressive drivers.\n",
      "* Consider purchasing travel insurance that covers vehicle damage or theft.\n",
      "* Don't drink and drive - Jamaica has strict laws against drunk driving.\n",
      "\n",
      "This was developed by Tahj Gordon.\n"
     ]
    }
   ],
   "source": [
    "query = \"How will I drive in Jamaica?\"\n",
    "print(generate_llama_recommendation(query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82966aa-3dec-4663-9116-832a45d0503c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
